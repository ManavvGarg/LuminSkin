{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinCancer Image Classification using ViT (Vision Transformers and CNNs): Achieving SOTA in Vision Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing vit_pytorch released by @lucidrains on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:51:12.562019Z",
     "iopub.status.busy": "2024-04-26T09:51:12.561652Z",
     "iopub.status.idle": "2024-04-26T09:51:26.342188Z",
     "shell.execute_reply": "2024-04-26T09:51:26.341044Z",
     "shell.execute_reply.started": "2024-04-26T09:51:12.561989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install vit_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Torch and Changing Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:51:26.344709Z",
     "iopub.status.busy": "2024-04-26T09:51:26.344397Z",
     "iopub.status.idle": "2024-04-26T09:51:29.807647Z",
     "shell.execute_reply": "2024-04-26T09:51:29.806648Z",
     "shell.execute_reply.started": "2024-04-26T09:51:26.344680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:51:29.809119Z",
     "iopub.status.busy": "2024-04-26T09:51:29.808755Z",
     "iopub.status.idle": "2024-04-26T09:51:29.840973Z",
     "shell.execute_reply": "2024-04-26T09:51:29.839922Z",
     "shell.execute_reply.started": "2024-04-26T09:51:29.809095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:51:29.844435Z",
     "iopub.status.busy": "2024-04-26T09:51:29.843922Z",
     "iopub.status.idle": "2024-04-26T09:51:30.977698Z",
     "shell.execute_reply": "2024-04-26T09:51:30.976334Z",
     "shell.execute_reply.started": "2024-04-26T09:51:29.844409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_images_in_classes(directory):\n",
    "    classes = os.listdir(directory)\n",
    "    class_counts = {}\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_counts[class_name] = len(os.listdir(class_dir))\n",
    "    return class_counts\n",
    "\n",
    "def plot_pie_chart(class_counts, setN):\n",
    "    labels = class_counts.keys()\n",
    "    sizes = class_counts.values()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'Distribution of Images of each class in {setN} Set')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "directory = \"/kaggle/input/skin-cancer-malignant-vs-benign/train\"\n",
    "class_counts = count_images_in_classes(directory)\n",
    "plot_pie_chart(class_counts, setN=\"Train\")\n",
    "\n",
    "directory2 = \"/kaggle/input/skin-cancer-malignant-vs-benign/test\"\n",
    "class_counts2 = count_images_in_classes(directory2)\n",
    "plot_pie_chart(class_counts2, setN=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:51:30.980414Z",
     "iopub.status.busy": "2024-04-26T09:51:30.979688Z",
     "iopub.status.idle": "2024-04-26T09:52:17.194140Z",
     "shell.execute_reply": "2024-04-26T09:52:17.193116Z",
     "shell.execute_reply.started": "2024-04-26T09:51:30.980377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def augment_image(image_path, output_dir, prefix='', num_augmentations=5):\n",
    "    image = Image.open(image_path)\n",
    "    image_name = os.path.basename(image_path)\n",
    "    \n",
    "    # Save original image\n",
    "    original_image_path = os.path.join(output_dir, prefix + image_name)\n",
    "    image.save(original_image_path)\n",
    "    \n",
    "    # Define transformations for augmentation\n",
    "    transformations = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.RandomPerspective(),\n",
    "    ])\n",
    "    \n",
    "    # Augment and save the image\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_image = transformations(image)\n",
    "        augmented_image_name = f\"{prefix}{i+1}_{image_name}\"\n",
    "        augmented_image_path = os.path.join(output_dir, augmented_image_name)\n",
    "        augmented_image.save(augmented_image_path)\n",
    "\n",
    "def balance_dataset(input_dir, output_dir):\n",
    "    # Create output directories if they don't exist\n",
    "    for subdir in ['benign', 'malignant']:\n",
    "        os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    # Count the number of samples in each class\n",
    "    benign_images = [f for f in os.listdir(os.path.join(input_dir, 'benign')) if f.endswith('.jpg')]\n",
    "    malignant_images = [f for f in os.listdir(os.path.join(input_dir, 'malignant')) if f.endswith('.jpg')]\n",
    "    \n",
    "    num_benign = len(benign_images)\n",
    "    num_malignant = len(malignant_images)\n",
    "    \n",
    "    # Calculate the augmentation factor\n",
    "    augmentation_factor = max(num_benign, num_malignant) // min(num_benign, num_malignant)\n",
    "    \n",
    "    # Augment both classes\n",
    "    for image_name in benign_images:\n",
    "        image_path = os.path.join(input_dir, 'benign', image_name)\n",
    "        augment_image(image_path, os.path.join(output_dir, 'benign'), prefix='', num_augmentations=augmentation_factor)\n",
    "    \n",
    "    for image_name in malignant_images:\n",
    "        image_path = os.path.join(input_dir, 'malignant', image_name)\n",
    "        augment_image(image_path, os.path.join(output_dir, 'malignant'), prefix='', num_augmentations=augmentation_factor)\n",
    "\n",
    "\n",
    "input_dir = \"/kaggle/input/skin-cancer-malignant-vs-benign/train\"\n",
    "output_dir = \"/kaggle/working/balanced_train\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "balance_dataset(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization after data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:52:17.195903Z",
     "iopub.status.busy": "2024-04-26T09:52:17.195496Z",
     "iopub.status.idle": "2024-04-26T09:52:17.406738Z",
     "shell.execute_reply": "2024-04-26T09:52:17.405832Z",
     "shell.execute_reply.started": "2024-04-26T09:52:17.195877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_images_in_classes(directory):\n",
    "    classes = os.listdir(directory)\n",
    "    class_counts = {}\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_counts[class_name] = len(os.listdir(class_dir))\n",
    "    return class_counts\n",
    "\n",
    "def plot_histogram(class_counts):\n",
    "    labels = class_counts.keys()\n",
    "    sizes = class_counts.values()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, sizes)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Distribution of Images in Each Class')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "directory = \"/kaggle/working/balanced_train\"\n",
    "class_counts = count_images_in_classes(directory)\n",
    "plot_histogram(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 random images from augmented data class \"benign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:52:17.408157Z",
     "iopub.status.busy": "2024-04-26T09:52:17.407901Z",
     "iopub.status.idle": "2024-04-26T09:52:18.065838Z",
     "shell.execute_reply": "2024-04-26T09:52:18.064949Z",
     "shell.execute_reply.started": "2024-04-26T09:52:17.408135Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_dir = \"/kaggle/working/balanced_train/benign/\"\n",
    "image_files = os.listdir(image_dir)\n",
    "random_image_files = random.sample(image_files, 5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))  # Adjust figsize as needed\n",
    "\n",
    "for i, image_file in enumerate(random_image_files):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()  # Ensures proper spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 random images from augmented data class \"malignant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:52:18.067681Z",
     "iopub.status.busy": "2024-04-26T09:52:18.067000Z",
     "iopub.status.idle": "2024-04-26T09:52:18.756730Z",
     "shell.execute_reply": "2024-04-26T09:52:18.755637Z",
     "shell.execute_reply.started": "2024-04-26T09:52:18.067648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_dir = \"/kaggle/working/balanced_train/malignant/\"\n",
    "image_files = os.listdir(image_dir)\n",
    "random_image_files = random.sample(image_files, 5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))  # Adjust figsize as needed\n",
    "\n",
    "for i, image_file in enumerate(random_image_files):\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = Image.open(image_path)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()  # Ensures proper spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into memory. Images + Respective Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:52:18.758455Z",
     "iopub.status.busy": "2024-04-26T09:52:18.758154Z",
     "iopub.status.idle": "2024-04-26T09:52:18.770403Z",
     "shell.execute_reply": "2024-04-26T09:52:18.769345Z",
     "shell.execute_reply.started": "2024-04-26T09:52:18.758429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_SkinCancer_dataset(dataset_dir, batch_size=32, device='cuda'):\n",
    "    class_names = sorted(os.listdir(dataset_dir))\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over each class folder\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        image_names = os.listdir(class_dir)\n",
    "        num_images = len(image_names)\n",
    "        num_batches = (num_images + batch_size - 1) // batch_size\n",
    "\n",
    "        print(f\"Loading {num_images} images from class {class_name}...\")\n",
    "\n",
    "        # Iterate over each batch of images\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_image_names = image_names[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            # Load and preprocess each image in the batch\n",
    "            for image_name in batch_image_names:\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                try:\n",
    "                    image = Image.open(image_path)\n",
    "                    image = image.resize((256, 256))  # Resize image to desired size\n",
    "                    image = np.array(image) / 255.0  # Normalize pixel values\n",
    "                    batch_images.append(image)\n",
    "                    batch_labels.append(i)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "\n",
    "            # Append batch to images and labels lists\n",
    "            if batch_images:\n",
    "                images.append(np.array(batch_images))\n",
    "                labels.append(np.array(batch_labels))\n",
    "        print(f\"Done Loading {num_images} images from class {class_name}...\")\n",
    "    # Concatenate batches into single arrays\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    images = torch.tensor(np.transpose(images, (0, 3, 1, 2)), dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    \n",
    "    print(\"==============\\nDone loading all images and labels in memory\\n==============\")\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. augmented train directory\n",
    "1. normal train directory\n",
    "1. test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:52:18.773111Z",
     "iopub.status.busy": "2024-04-26T09:52:18.772828Z",
     "iopub.status.idle": "2024-04-26T09:53:06.700003Z",
     "shell.execute_reply": "2024-04-26T09:53:06.698982Z",
     "shell.execute_reply.started": "2024-04-26T09:52:18.773087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "aug_train_dataset_dir = \"/kaggle/working/balanced_train\"\n",
    "train_dataset_dir = \"/kaggle/input/skin-cancer-malignant-vs-benign/train\"\n",
    "test_dataset_dir = \"/kaggle/input/skin-cancer-malignant-vs-benign/test\"\n",
    "\n",
    "print(\"\\n========= Loading Augmented Train Dataset =========\\n\")\n",
    "\n",
    "# Load train dataset\n",
    "images_train, labels_train = load_SkinCancer_dataset(aug_train_dataset_dir)\n",
    "\n",
    "print(\"\\n========= Loading Train Dataset =========\\n\")\n",
    "\n",
    "# Load train dataset\n",
    "images_train2, labels_train2 = load_SkinCancer_dataset(train_dataset_dir)\n",
    "\n",
    "print(\"\\n========= Loading Test Dataset =========\\n\")\n",
    "\n",
    "# Load test dataset\n",
    "images_test, labels_test = load_SkinCancer_dataset(test_dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:53:06.701388Z",
     "iopub.status.busy": "2024-04-26T09:53:06.701083Z",
     "iopub.status.idle": "2024-04-26T09:53:06.714113Z",
     "shell.execute_reply": "2024-04-26T09:53:06.713351Z",
     "shell.execute_reply.started": "2024-04-26T09:53:06.701362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision.transforms import transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from vit_pytorch import ViT, deepvit\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class definition for SkinCancer dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:51.567758Z",
     "iopub.status.busy": "2024-04-26T09:55:51.567404Z",
     "iopub.status.idle": "2024-04-26T09:55:51.575480Z",
     "shell.execute_reply": "2024-04-26T09:55:51.574210Z",
     "shell.execute_reply.started": "2024-04-26T09:55:51.567728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SkinCancer(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:51.951189Z",
     "iopub.status.busy": "2024-04-26T09:55:51.950806Z",
     "iopub.status.idle": "2024-04-26T09:55:51.955872Z",
     "shell.execute_reply": "2024-04-26T09:55:51.954868Z",
     "shell.execute_reply.started": "2024-04-26T09:55:51.951158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Skin Cancer train and non augmented train dataset instance\n",
    "sc_train = SkinCancer(images_train, labels_train)\n",
    "sc_train_non_aug = SkinCancer(images_train2, labels_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:52.943693Z",
     "iopub.status.busy": "2024-04-26T09:55:52.943317Z",
     "iopub.status.idle": "2024-04-26T09:55:52.948046Z",
     "shell.execute_reply": "2024-04-26T09:55:52.947012Z",
     "shell.execute_reply.started": "2024-04-26T09:55:52.943662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Skin Cancer test dataset instance\n",
    "sc_test = SkinCancer(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:54.285902Z",
     "iopub.status.busy": "2024-04-26T09:55:54.285542Z",
     "iopub.status.idle": "2024-04-26T09:55:54.291249Z",
     "shell.execute_reply": "2024-04-26T09:55:54.290341Z",
     "shell.execute_reply.started": "2024-04-26T09:55:54.285875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create data loaders for each split\n",
    "train_loader = DataLoader(sc_train, batch_size=32, shuffle=True)\n",
    "non_aug_train_loader = DataLoader(sc_train_non_aug, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(sc_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition. Note:- This model is not a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:57.105922Z",
     "iopub.status.busy": "2024-04-26T09:55:57.105588Z",
     "iopub.status.idle": "2024-04-26T09:55:58.242590Z",
     "shell.execute_reply": "2024-04-26T09:55:58.241549Z",
     "shell.execute_reply.started": "2024-04-26T09:55:57.105898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "v = ViT(\n",
    "    image_size = 256,\n",
    "    channels = 3,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "    emb_dropout = 0.5\n",
    ").to(device)\n",
    "\n",
    "non_aug_v = ViT(\n",
    "    image_size = 256,\n",
    "    channels = 3,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "    emb_dropout = 0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:55:58.891792Z",
     "iopub.status.busy": "2024-04-26T09:55:58.890955Z",
     "iopub.status.idle": "2024-04-26T09:56:00.000749Z",
     "shell.execute_reply": "2024-04-26T09:55:59.999932Z",
     "shell.execute_reply.started": "2024-04-26T09:55:58.891748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "deepv = deepvit.DeepViT(\n",
    "    image_size = 256,\n",
    "    channels = 3,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "    emb_dropout = 0.5\n",
    ").to(device)\n",
    "\n",
    "non_aug_deepv = deepvit.DeepViT(\n",
    "    image_size = 256,\n",
    "    channels = 3,\n",
    "    patch_size = 32,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "    emb_dropout = 0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:56:00.002928Z",
     "iopub.status.busy": "2024-04-26T09:56:00.002348Z",
     "iopub.status.idle": "2024-04-26T09:56:00.009821Z",
     "shell.execute_reply": "2024-04-26T09:56:00.008975Z",
     "shell.execute_reply.started": "2024-04-26T09:56:00.002894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(v.parameters(), lr=0.0001)\n",
    "optimizer2 = optim.Adam(deepv.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:56:02.174703Z",
     "iopub.status.busy": "2024-04-26T09:56:02.173875Z",
     "iopub.status.idle": "2024-04-26T09:56:02.178840Z",
     "shell.execute_reply": "2024-04-26T09:56:02.177880Z",
     "shell.execute_reply.started": "2024-04-26T09:56:02.174672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:56:07.695473Z",
     "iopub.status.busy": "2024-04-26T09:56:07.694749Z",
     "iopub.status.idle": "2024-04-26T09:56:07.699369Z",
     "shell.execute_reply": "2024-04-26T09:56:07.698353Z",
     "shell.execute_reply.started": "2024-04-26T09:56:07.695440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dataset\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:58:26.663116Z",
     "iopub.status.busy": "2024-04-26T09:58:26.662751Z",
     "iopub.status.idle": "2024-04-26T10:03:39.297103Z",
     "shell.execute_reply": "2024-04-26T10:03:39.296061Z",
     "shell.execute_reply.started": "2024-04-26T09:58:26.663086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store test loss and accuracy\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    v.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = v(images)  # Forward pass\n",
    "        loss1 = criterion(outputs, labels)\n",
    "        total_loss = loss1 \n",
    "        total_loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_accuracy_history.append(epoch_accuracy)\n",
    "    print(f'Training: Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss curve on augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:04:23.392524Z",
     "iopub.status.busy": "2024-04-26T10:04:23.392148Z",
     "iopub.status.idle": "2024-04-26T10:04:23.671814Z",
     "shell.execute_reply": "2024-04-26T10:04:23.670880Z",
     "shell.execute_reply.started": "2024-04-26T10:04:23.392492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, train_loss_history, color=\"red\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training accuracy curve on augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:04:25.884795Z",
     "iopub.status.busy": "2024-04-26T10:04:25.884395Z",
     "iopub.status.idle": "2024-04-26T10:04:26.120265Z",
     "shell.execute_reply": "2024-04-26T10:04:26.119339Z",
     "shell.execute_reply.started": "2024-04-26T10:04:25.884765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, train_accuracy_history, color=\"blue\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:15:59.672902Z",
     "iopub.status.busy": "2024-04-26T10:15:59.672529Z",
     "iopub.status.idle": "2024-04-26T10:21:53.973630Z",
     "shell.execute_reply": "2024-04-26T10:21:53.972718Z",
     "shell.execute_reply.started": "2024-04-26T10:15:59.672873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store test loss and accuracy\n",
    "train_loss_history_deepv = []\n",
    "train_accuracy_history_deepv = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    v.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = deepv(images)  # Forward pass\n",
    "        loss1 = criterion(outputs, labels)\n",
    "        total_loss = loss1 \n",
    "        total_loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    train_loss_history_deepv.append(epoch_loss)\n",
    "    train_accuracy_history_deepv.append(epoch_accuracy)\n",
    "    print(f'Training: Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss curve on augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:09.357937Z",
     "iopub.status.busy": "2024-04-26T10:24:09.357223Z",
     "iopub.status.idle": "2024-04-26T10:24:09.569916Z",
     "shell.execute_reply": "2024-04-26T10:24:09.568992Z",
     "shell.execute_reply.started": "2024-04-26T10:24:09.357905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, train_loss_history_deepv, color=\"red\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training accuracy curve on augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:07.112127Z",
     "iopub.status.busy": "2024-04-26T10:24:07.111272Z",
     "iopub.status.idle": "2024-04-26T10:24:07.341639Z",
     "shell.execute_reply": "2024-04-26T10:24:07.340719Z",
     "shell.execute_reply.started": "2024-04-26T10:24:07.112095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, train_accuracy_history_deepv, color=\"blue\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non augmented dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:04:29.034797Z",
     "iopub.status.busy": "2024-04-26T10:04:29.034368Z",
     "iopub.status.idle": "2024-04-26T10:06:57.758768Z",
     "shell.execute_reply": "2024-04-26T10:06:57.757896Z",
     "shell.execute_reply.started": "2024-04-26T10:04:29.034766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store test loss and accuracy\n",
    "non_aug_train_loss_history = []\n",
    "non_aug_train_accuracy_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    non_aug_v.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for images, labels in tqdm(non_aug_train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = non_aug_v(images)  # Forward pass\n",
    "        loss1 = criterion(outputs, labels)\n",
    "        total_loss = loss1 \n",
    "        total_loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    non_aug_train_loss_history.append(epoch_loss)\n",
    "    non_aug_train_accuracy_history.append(epoch_accuracy)\n",
    "    print(f'Training: Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss curve on non-augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:07:14.751497Z",
     "iopub.status.busy": "2024-04-26T10:07:14.751126Z",
     "iopub.status.idle": "2024-04-26T10:07:15.030077Z",
     "shell.execute_reply": "2024-04-26T10:07:15.029085Z",
     "shell.execute_reply.started": "2024-04-26T10:07:14.751468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, non_aug_train_loss_history, color=\"red\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training accuracy curve on non-augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:07:17.251707Z",
     "iopub.status.busy": "2024-04-26T10:07:17.251346Z",
     "iopub.status.idle": "2024-04-26T10:07:17.473135Z",
     "shell.execute_reply": "2024-04-26T10:07:17.472211Z",
     "shell.execute_reply.started": "2024-04-26T10:07:17.251677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, non_aug_train_accuracy_history, color=\"blue\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep vision transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:07:31.901919Z",
     "iopub.status.busy": "2024-04-26T10:07:31.901547Z",
     "iopub.status.idle": "2024-04-26T10:13:25.976690Z",
     "shell.execute_reply": "2024-04-26T10:13:25.975942Z",
     "shell.execute_reply.started": "2024-04-26T10:07:31.901890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store train loss and accuracy\n",
    "non_aug_train_loss_history_deepv = []\n",
    "non_aug_train_accuracy_history_deepv = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    non_aug_deepv.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "        optimizer2.zero_grad()  # Clear gradients\n",
    "        outputs = non_aug_deepv(images)  # Forward pass\n",
    "        loss1 = criterion(outputs, labels)\n",
    "        total_loss = loss1 \n",
    "        total_loss.backward()  # Backpropagation\n",
    "        optimizer2.step()  # Update model parameters\n",
    "        running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    non_aug_train_loss_history_deepv.append(epoch_loss)\n",
    "    non_aug_train_accuracy_history_deepv.append(epoch_accuracy)\n",
    "    print(f'Training: Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss curve on non-augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:15:39.276778Z",
     "iopub.status.busy": "2024-04-26T10:15:39.275973Z",
     "iopub.status.idle": "2024-04-26T10:15:39.570909Z",
     "shell.execute_reply": "2024-04-26T10:15:39.569939Z",
     "shell.execute_reply.started": "2024-04-26T10:15:39.276744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, non_aug_train_loss_history_deepv, color=\"red\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training accuracy curve on non-augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:15:41.358165Z",
     "iopub.status.busy": "2024-04-26T10:15:41.357542Z",
     "iopub.status.idle": "2024-04-26T10:15:41.588264Z",
     "shell.execute_reply": "2024-04-26T10:15:41.587185Z",
     "shell.execute_reply.started": "2024-04-26T10:15:41.358133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(0, num_epochs))\n",
    "plt.plot(epochs, non_aug_train_accuracy_history_deepv, color=\"blue\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ViT Testing (Augemnted Dataset Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:21.861545Z",
     "iopub.status.busy": "2024-04-26T10:24:21.860820Z",
     "iopub.status.idle": "2024-04-26T10:24:22.702606Z",
     "shell.execute_reply": "2024-04-26T10:24:22.701754Z",
     "shell.execute_reply.started": "2024-04-26T10:24:21.861510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store predictions and ground truths\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Testing loop\n",
    "v.eval()  # Set model to evaluation mode\n",
    "test_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        outputs = v(images)  # Forward pass\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(predicted_labels.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "        loss1 = criterion(outputs, labels)  # Compute loss 1\n",
    "        total_loss = loss1\n",
    "        test_running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted labels\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate test loss and accuracy for the current epoch\n",
    "    test_loss = test_running_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "# Print test loss, accuracy, correct predictions, and total predictions\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Correct Predictions: {correct}, Total Predictions: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ViT Testing (Non Augemnted Dataset Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:29.337051Z",
     "iopub.status.busy": "2024-04-26T10:24:29.336703Z",
     "iopub.status.idle": "2024-04-26T10:24:30.185356Z",
     "shell.execute_reply": "2024-04-26T10:24:30.184214Z",
     "shell.execute_reply.started": "2024-04-26T10:24:29.337025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store predictions and ground truths\n",
    "predictions_non_aug = []\n",
    "true_labels_non_aug = []\n",
    "\n",
    "# Testing loop\n",
    "non_aug_v.eval()  # Set model to evaluation mode\n",
    "test_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        outputs = non_aug_v(images)  # Forward pass\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        predictions_non_aug.extend(predicted_labels.tolist())\n",
    "        true_labels_non_aug.extend(labels.tolist())\n",
    "        loss1 = criterion(outputs, labels)  # Compute loss 1\n",
    "        total_loss = loss1\n",
    "        test_running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted labels\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate test loss and accuracy for the current epoch\n",
    "    test_loss = test_running_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "# Print test loss, accuracy, correct predictions, and total predictions\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Correct Predictions: {correct}, Total Predictions: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep ViT testing (Augmented Dataset Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:32.017614Z",
     "iopub.status.busy": "2024-04-26T10:24:32.017222Z",
     "iopub.status.idle": "2024-04-26T10:24:33.011900Z",
     "shell.execute_reply": "2024-04-26T10:24:33.011019Z",
     "shell.execute_reply.started": "2024-04-26T10:24:32.017583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store predictions and ground truths\n",
    "predictions_deepv = []\n",
    "true_labels_deepv = []\n",
    "\n",
    "# Testing loop\n",
    "deepv.eval()  # Set model to evaluation mode\n",
    "test_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        outputs = deepv(images)  # Forward pass\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        predictions_deepv.extend(predicted_labels.tolist())\n",
    "        true_labels_deepv.extend(labels.tolist())\n",
    "        loss1 = criterion(outputs, labels)  # Compute loss 1\n",
    "        total_loss = loss1\n",
    "        test_running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted labels\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate test loss and accuracy for the current epoch\n",
    "    test_loss = test_running_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "# Print test loss, accuracy, correct predictions, and total predictions\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Correct Predictions: {correct}, Total Predictions: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep ViT testing (Non Augmented Dataset Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:34.061326Z",
     "iopub.status.busy": "2024-04-26T10:24:34.060608Z",
     "iopub.status.idle": "2024-04-26T10:24:35.050386Z",
     "shell.execute_reply": "2024-04-26T10:24:35.049530Z",
     "shell.execute_reply.started": "2024-04-26T10:24:34.061276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store predictions and ground truths\n",
    "predictions_deepv_non_aug = []\n",
    "true_labels_deepv_non_aug = []\n",
    "\n",
    "# Testing loop\n",
    "non_aug_deepv.eval()  # Set model to evaluation mode\n",
    "test_running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        outputs = non_aug_deepv(images)  # Forward pass\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        predictions_deepv_non_aug.extend(predicted_labels.tolist())\n",
    "        true_labels_deepv_non_aug.extend(labels.tolist())\n",
    "        loss1 = criterion(outputs, labels)  # Compute loss 1\n",
    "        total_loss = loss1\n",
    "        test_running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted labels\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate test loss and accuracy for the current epoch\n",
    "    test_loss = test_running_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "# Print test loss, accuracy, correct predictions, and total predictions\n",
    "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, Correct Predictions: {correct}, Total Predictions: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:36.044262Z",
     "iopub.status.busy": "2024-04-26T10:24:36.043563Z",
     "iopub.status.idle": "2024-04-26T10:24:40.063729Z",
     "shell.execute_reply": "2024-04-26T10:24:40.062753Z",
     "shell.execute_reply.started": "2024-04-26T10:24:36.044230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ViT confusion matrix (Augmented Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:42.480509Z",
     "iopub.status.busy": "2024-04-26T10:24:42.479969Z",
     "iopub.status.idle": "2024-04-26T10:24:42.852491Z",
     "shell.execute_reply": "2024-04-26T10:24:42.851555Z",
     "shell.execute_reply.started": "2024-04-26T10:24:42.480478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert true labels and predictions to tensors\n",
    "true_labels_tensor_v = torch.tensor(true_labels)\n",
    "predictions_tensor_v = torch.tensor(predictions)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = torchmetrics.functional.confusion_matrix(true_labels_tensor_v, predictions_tensor_v, num_classes=2, task='MULTICLASS', normalize=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ViT confusion matrix (Non Augmented Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:45.004093Z",
     "iopub.status.busy": "2024-04-26T10:24:45.003729Z",
     "iopub.status.idle": "2024-04-26T10:24:45.271925Z",
     "shell.execute_reply": "2024-04-26T10:24:45.271102Z",
     "shell.execute_reply.started": "2024-04-26T10:24:45.004064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert true labels and predictions to tensors\n",
    "true_labels_tensor_v_non_aug = torch.tensor(true_labels_non_aug)\n",
    "predictions_tensor_v_non_aug = torch.tensor(predictions_non_aug)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = torchmetrics.functional.confusion_matrix(true_labels_tensor_v_non_aug, predictions_tensor_v_non_aug, num_classes=2, task='MULTICLASS', normalize=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep ViT confusion matrix (Augmented Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:46.678620Z",
     "iopub.status.busy": "2024-04-26T10:24:46.677802Z",
     "iopub.status.idle": "2024-04-26T10:24:46.959605Z",
     "shell.execute_reply": "2024-04-26T10:24:46.958662Z",
     "shell.execute_reply.started": "2024-04-26T10:24:46.678585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert true labels and predictions to tensors\n",
    "true_labels_tensor_deepv = torch.tensor(true_labels_deepv)\n",
    "predictions_tensor_deepv = torch.tensor(predictions_deepv)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = torchmetrics.functional.confusion_matrix(true_labels_tensor_deepv, predictions_tensor_deepv, num_classes=2, task='MULTICLASS', normalize=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep ViT confusion matrix (Non Augmented Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:47.917577Z",
     "iopub.status.busy": "2024-04-26T10:24:47.917207Z",
     "iopub.status.idle": "2024-04-26T10:24:48.190630Z",
     "shell.execute_reply": "2024-04-26T10:24:48.189695Z",
     "shell.execute_reply.started": "2024-04-26T10:24:47.917547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert true labels and predictions to tensors\n",
    "true_labels_tensor_deepv_non_aug = torch.tensor(true_labels_deepv_non_aug)\n",
    "predictions_tensor_deepv_non_aug = torch.tensor(predictions_deepv_non_aug)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = torchmetrics.functional.confusion_matrix(true_labels_tensor_deepv_non_aug, predictions_tensor_deepv_non_aug, num_classes=2, task='MULTICLASS', normalize=None)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying images from a custom dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset was made combining random images from \"bening\" class and \"malignant\" into a single folder.\n",
    "* 45-127 : Bening\n",
    "* 185-247 : Malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base ViT (Augemnted Dataset Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:24:53.140745Z",
     "iopub.status.busy": "2024-04-26T10:24:53.140373Z",
     "iopub.status.idle": "2024-04-26T10:24:53.639791Z",
     "shell.execute_reply": "2024-04-26T10:24:53.638861Z",
     "shell.execute_reply.started": "2024-04-26T10:24:53.140716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the folder containing the images\n",
    "folder_path = '/kaggle/input/skincancer-custom/custom_test'  # Replace with the path to the folder containing the images\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through all .jpg files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Preprocess the image\n",
    "        input_image = preprocess(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "        # Forward pass the preprocessed image through the model\n",
    "        with torch.no_grad():\n",
    "            v.eval()  # Set model to evaluation mode\n",
    "            outputs = v(input_image)\n",
    "\n",
    "        # Post-process the predicted output to get the final prediction result\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append((filename, predicted_class))\n",
    "\n",
    "# Sort the results based on image names\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the sorted results\n",
    "for filename, predicted_class in results:\n",
    "    print(f'Image: {filename}, Predicted class: {\"Malignant\" if predicted_class == 1 else \"Benign\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can conclude that our model has an accuracy of: 93.54838709677419%\n",
    "---------------------------------------------------------------------\n",
    "Accuracy=(Total Number of Predictions / Number of Correct Predictions)×100%\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "However, We can see that our Model confused in classifying 2 images (119.jpg and 186.jpg) and made in correct predictions.\n",
    "\n",
    "119.jpg\n",
    "* Correct Class: Benign\n",
    "* Predicted Class: Malignant\n",
    "\n",
    "186.jpg\n",
    "* Correct Class: Malignant\n",
    "* Predicted Class: Bening\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:25:28.560169Z",
     "iopub.status.busy": "2024-04-26T10:25:28.559354Z",
     "iopub.status.idle": "2024-04-26T10:25:28.747811Z",
     "shell.execute_reply": "2024-04-26T10:25:28.746825Z",
     "shell.execute_reply.started": "2024-04-26T10:25:28.560138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = \"/kaggle/input/skincancer-custom/custom_test/119.jpg\" \n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T10:25:28.836722Z",
     "iopub.status.busy": "2024-04-26T10:25:28.836407Z",
     "iopub.status.idle": "2024-04-26T10:25:28.965000Z",
     "shell.execute_reply": "2024-04-26T10:25:28.964118Z",
     "shell.execute_reply.started": "2024-04-26T10:25:28.836697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_path = \"/kaggle/input/skincancer-custom/custom_test/186.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can conclude that our model confuses between the two due to their similarity in discoloration of the skin"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 174469,
     "sourceId": 505351,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4818332,
     "sourceId": 8147674,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
